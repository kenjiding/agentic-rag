# AI Agent & RAG 领域面试题答案汇总

本目录包含AI Agent和RAG领域相关面试题的详细答案和分析。

## 文档结构

### 1. LLM基础架构与训练
- **文件**: `01-LLM基础架构与训练.md`
- **内容**:
  - 问题1: 介绍LLM Decoder-Only架构
  - 问题2: 你对SFT的理解是什么?与预训练相比有什么差异?

### 2. SFT数据集构造与优化
- **文件**: `02-SFT数据集构造与优化.md`
- **内容**:
  - 问题3: SFT冷启动时数据集构造需要注意哪些因素?为什么要做数据清洗与均衡采样?

### 3. RAG系统与优化
- **文件**: `03-RAG系统与优化.md`
- **内容**:
  - 问题4: 介绍一下RAG的整体流程。在Agent落地场景中,RAG会遇到哪些延迟和正确率问题?你怎么优化召回链路?

### 4. 数据集自动化与多Agent系统
- **文件**: `04-数据集自动化与多Agent系统.md`
- **内容**:
  - 问题5: 在你的问答Agent项目中,数据集构造的自动化流程是怎么实现的?
  - 问题6: 你是如何利用多Agent协同来提高推理正确率的? 调度策略如何实现?

### 5. 分布式训练与优化技术
- **文件**: `05-分布式训练与优化技术.md`
- **内容**:
  - 问题7: 你提到用DeepSpeed做SFT训练,请讲一下DeepSpeed ZeRO Stage 1-3的区别,以及什么时候用FSDP会更好?

### 6. Prompt优化与评估
- **文件**: `06-Prompt优化与评估.md`
- **内容**:
  - 问题8: 你做Prompt优化时,是如何判断优化后的Prompt在Agent推理链路中性能提升的?用什么指标来衡量?

### 7. 注意力机制与推理优化
- **文件**: `07-注意力机制与推理优化.md`
- **内容**:
  - 二面问题1: 自注意力机制是什么?计算复杂度怎么算?
  - 问题2: KV-Cache的如何加速推理?

## 待补充问题

以下问题将在后续文档中补充：

### 8. 参数高效微调技术
- 问题3: LoRA的原理是什么?与P-Tuning、Adapter的异同点?LoRA的参数选择对模型性能有何影响?

### 9. 强化学习与对齐
- 问题4: 介绍下RLHF的基本流程,与DPO的差异是什么?

### 10. 分布式训练策略
- 问题5: 分布式训练中的TP、PP、DP分别是什么?

### 11. 注意力优化技术
- 问题6: flash-attention的原理是什么?

### 12. 模型架构创新
- 问题7: DeepSeek的MoA架构与MoE有何区别?

### 13. Agent系统设计
- 问题8: agent实习主要负责哪些模块?
- 问题9: 在多Agent系统中,如何保证异步任务执行的稳定性和结果一致性?
- 问题10: 如果Agent推理API需要低延迟响应,你会从哪些方面做系统级优化?

### 14. 多模态系统
- 问题9: 记忆系统如何实现视觉-语言特征对齐?
- 问题10: 如果视觉模块误判,如何通过语言纠错?

### 15. 评估系统
- 问题11: 具体讲讲怎么构建evaluation pipeline的?

## 使用说明

1. 每个文档都包含：
   - 问题解析
   - 详细答案（由浅入深）
   - 代码示例
   - 实际应用场景
   - 总结

2. 答案特点：
   - 详细解释核心概念
   - 提供具体示例
   - 包含代码实现
   - 适合初学者理解

3. 建议阅读顺序：
   - 按照文档编号顺序阅读
   - 或根据自己感兴趣的主题选择阅读

## 更新日志

- 2025-01-XX: 初始版本，包含前7个文档

