import asyncio
import time
from langchain.agents import create_agent
from langchain_core.messages import AIMessage, ToolMessage
from langgraph.graph.state import RunnableConfig
from tools.rag import get_rag_tools

def format_debug_output(step_name: str, content: str, is_tool_call = False) -> None:
  if is_tool_call:
    print(f'ğŸ”„ ã€å·¥å…·è°ƒç”¨ã€‘ {step_name}')
    print("-" * 40)
    print(content.strip())
    print("-" * 40)
  else:
    print(f"ğŸ’­ ã€{step_name}ã€‘")
    print("-" * 40)
    print(content.strip())
    print("-" * 40)

async def create_chat_agent(tools: list):
  return create_agent(
    tools=tools,
    model="openai:gpt-4o-mini",
    system_prompt="You are a helpful assistant that can answer questions and help with tasks. you should use agentic rag tools to answer questions first."
  )

async def run_chat_agent():
  tools = await get_rag_tools()
  agent = await create_chat_agent(tools)
  session_id = "1"
  config = RunnableConfig(configurable={"thread_id": session_id}, recursion_limit=100)
  input_messages = [("user", "2019å¹´ç¦å¸ƒæ–¯å¯Œè±ªæ¦œæ°å¤«Â·è´ç´¢æ–¯è´¢å¯Œæ˜¯å¤šå°‘?")]
  res = agent.astream(input={"messages": input_messages}, config=config)
  async for chunk in res:
        print("=" * 60)
        items = chunk.items();
        for item in items:
          (model_name, model_output) = item;
          messages = model_output.get("messages", []);

          for message in messages:
            if isinstance(message, AIMessage):
              response_metadata = message.response_metadata
              print("å®ŒæˆåŸå› : ", f"{response_metadata.get("finish_reason", "")}, ", "ä½¿ç”¨çš„æ¨¡å‹: ", f"{response_metadata.get("model_name", "")}");
              tool_calls = message.tool_calls;
              if tool_calls and len(tool_calls) > 0:
                for tool_call in tool_calls:
                  tool_name = tool_call.get("name", "");
                  tool_input = tool_call.get("args", {});
                  print(f"å·¥å…·åç§°: {tool_name}")
                  print(f"å·¥å…·è¾“å…¥: {tool_input}")
                  print("-" * 60)

              print("\n")
              print("AI å›ç­”: ")
              print("-" * 60)
              print(message.content)
              print("-" * 60)
              usage_metadata = message.usage_metadata;
              print("input_tokens: ", f"{usage_metadata.get("input_tokens", "")}, ", "output_tokens: ", f"{usage_metadata.get("output_tokens", "")}");
          
            if isinstance(message, ToolMessage):
              # ä» ToolMessage ä¸­è·å–å·¥å…·åç§°
              tool_name = getattr(message, 'name', 'æœªçŸ¥å·¥å…·')
              tool_result = f"""
  ğŸ”§ å·¥å…·ï¼š{tool_name}
  ğŸ“¤ ç»“æœï¼š
  {message.content}
  âœ… çŠ¶æ€ï¼šæ‰§è¡Œå®Œæˆï¼Œå¯ä»¥å¼€å§‹ä¸‹ä¸€ä¸ªä»»åŠ¡
              """
              format_debug_output("å·¥å…·æ‰§è¡Œç»“æœ", tool_result, is_tool_call=True)

if __name__ == "__main__":
  asyncio.run(run_chat_agent())