"""FastAPI æœåŠ¡å™¨ - ä¸ºå‰ç«¯æä¾›æµå¼ API æ¥å£"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any
import json
import asyncio
import logging
from src.multi_agent.graph import MultiAgentGraph
from src.multi_agent.config import MultiAgentConfig

logger = logging.getLogger(__name__)

app = FastAPI(title="AI Agent API", version="1.0.0")

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€ MultiAgentGraph å®ä¾‹
_graph: Optional[MultiAgentGraph] = None
_graph_initializing = False
_graph_lock = asyncio.Lock()


async def get_graph() -> MultiAgentGraph:
    """è·å–æˆ–åˆ›å»º MultiAgentGraph å®ä¾‹ï¼ˆå¼‚æ­¥ï¼Œæ”¯æŒå¹¶å‘å®‰å…¨ï¼‰"""
    global _graph, _graph_initializing
    
    if _graph is not None:
        return _graph
    
    async with _graph_lock:
        # åŒé‡æ£€æŸ¥ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
        if _graph is not None:
            return _graph
        
        if _graph_initializing:
            # å¦‚æœæ­£åœ¨åˆå§‹åŒ–ï¼Œç­‰å¾…å®Œæˆ
            while _graph_initializing:
                await asyncio.sleep(0.1)
            return _graph
        
        _graph_initializing = True
        try:
            config = MultiAgentConfig()
            loop = asyncio.get_event_loop()
            
            def init_graph():
                return MultiAgentGraph(
                    llm=None,
                    max_iterations=config.max_iterations
                )
            
            _graph = await loop.run_in_executor(None, init_graph)
            return _graph
        except Exception as e:
            logger.error(f"MultiAgentGraph åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise
        finally:
            _graph_initializing = False


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    message: str
    session_id: Optional[str] = "default"
    stream: bool = True


def format_state_update(state_update: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¼å¼åŒ–çŠ¶æ€æ›´æ–°ä¸ºå‰ç«¯å‹å¥½çš„æ ¼å¼

    è¿”å›ç»Ÿä¸€çš„ç»“æ„åŒ–å“åº”ï¼š
    - æœ‰ç»“æ„åŒ–æ•°æ®æ—¶ï¼šcontent ä¸ºç®€çŸ­æè¿°ï¼Œæ•°æ®ï¿½ï¿½ response_data ä¸­
    - æ— ç»“æ„åŒ–æ•°æ®æ—¶ï¼šcontent ä¸º AI ç”Ÿæˆçš„å®Œæ•´å›å¤
    """
    result = {
        "type": "state_update",
        "data": {
            "response_type": "text",
            "response_data": {}
        }
    }

    # æå–æ¶ˆæ¯ - æŸ¥æ‰¾æœ€åä¸€æ¡ AI æ¶ˆæ¯
    messages = state_update.get("messages", [])
    has_products = False
    has_orders = False

    if messages:
        from langchain_core.messages import AIMessage, ToolMessage

        # å…ˆæå–å·¥å…·ç»“æœä¸­çš„ç»“æ„åŒ–æ•°æ®
        for message in messages:
            if isinstance(message, ToolMessage):
                try:
                    tool_content = message.content
                    if isinstance(tool_content, str):
                        try:
                            tool_result = json.loads(tool_content)
                        except:
                            continue

                        if isinstance(tool_result, dict):
                            if "products" in tool_result:
                                products = tool_result.get("products", [])
                                if products:
                                    result["data"]["response_data"]["products"] = products
                                    has_products = True
                            if "orders" in tool_result:
                                orders = tool_result.get("orders", [])
                                if orders:
                                    result["data"]["response_data"]["orders"] = orders
                                    has_orders = True
                except Exception:
                    pass

        # æå–æ–‡æœ¬å†…å®¹
        ai_messages = [msg for msg in messages if isinstance(msg, AIMessage)]
        if ai_messages:
            last_ai_message = ai_messages[-1]
            if hasattr(last_ai_message, "content") and last_ai_message.content:
                ai_content = last_ai_message.content

                # å½“æœ‰ç»“æ„åŒ–æ•°æ®æ—¶ï¼Œcontent å·²ç»æ˜¯å·¥å…·çš„ç®€çŸ­æè¿°
                # ç›´æ¥ä½¿ç”¨å³å¯ï¼Œæ— éœ€é¢å¤–å¤„ç†
                result["data"]["content"] = ai_content
                result["data"]["role"] = "assistant"
        elif isinstance(messages[-1], dict):
            result["data"]["content"] = messages[-1].get("content", "")
            result["data"]["role"] = messages[-1].get("type", "assistant")

    # ç¡®å®šå“åº”ç±»å‹
    if has_products and has_orders:
        result["data"]["response_type"] = "mixed"
    elif has_products:
        result["data"]["response_type"] = "product_list"
    elif has_orders:
        result["data"]["response_type"] = "order_list"

    # æå–å…¶ä»–ä¿¡æ¯
    if current_agent := state_update.get("current_agent"):
        result["data"]["current_agent"] = current_agent
    if tools_used := state_update.get("tools_used", []):
        result["data"]["tools_used"] = tools_used

    return result


async def stream_chat_response(question: str, session_id: str):
    """æµå¼ç”ŸæˆèŠå¤©å“åº”"""
    try:
        graph = await get_graph()
        accumulated_state = {}
        execution_steps: list[str] = []
        step_details: list[dict] = []

        def add_step(step_name: str, detail: str = "") -> bool:
            """æ·»åŠ æ‰§è¡Œæ­¥éª¤ï¼Œè¿”å›æ˜¯å¦æ˜¯æ–°æ­¥éª¤"""
            if step_name and step_name not in execution_steps:
                execution_steps.append(step_name)
                step_details.append({"name": step_name, "detail": detail, "status": "running"})
                # æ›´æ–°ä¹‹å‰æ­¥éª¤çš„çŠ¶æ€ä¸ºå®Œæˆ
                for i in range(len(step_details) - 1):
                    step_details[i]["status"] = "completed"
                return True
            return False

        # ç«‹å³å‘é€åˆå§‹çŠ¶æ€
        initial_step = "ğŸš€ å¼€å§‹åˆ†ææ‚¨çš„é—®é¢˜"
        add_step(initial_step)
        yield f"data: {json.dumps({'type': 'state_update', 'data': {'execution_steps': execution_steps, 'step_details': step_details}}, ensure_ascii=False)}\n\n"

        # ä½¿ç”¨ updates æ¨¡å¼è·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ›´æ–°
        async for state_update in graph.astream(question, stream_mode="updates"):
            # LangGraph è¿”å›çš„æ ¼å¼æ˜¯ {node_name: {updated_fields}}
            for node_name, node_update in state_update.items():
                # è·³è¿‡ç‰¹æ®ŠèŠ‚ç‚¹
                if node_name in ("__start__", "__end__"):
                    continue

                # ç”Ÿæˆæ­¥éª¤åç§°å’Œè¯¦æƒ…
                step_name = _format_step_name(node_name, node_update)
                step_detail = _format_step_detail(node_name, node_update)

                if step_name:
                    is_new_step = add_step(step_name, step_detail)
                    # å¦‚æœæœ‰æ–°æ­¥éª¤ï¼Œç«‹å³å‘é€
                    if is_new_step:
                        yield f"data: {json.dumps({'type': 'state_update', 'data': {'execution_steps': execution_steps, 'step_details': step_details}}, ensure_ascii=False)}\n\n"

                # ç´¯ç§¯çŠ¶æ€
                if isinstance(node_update, dict):
                    if "messages" in node_update and "messages" in accumulated_state:
                        existing_messages = accumulated_state.get("messages", [])
                        new_messages = node_update.get("messages", [])
                        existing_ids = {id(msg) if hasattr(msg, 'id') else str(msg) for msg in existing_messages}
                        for msg in new_messages:
                            msg_id = id(msg) if hasattr(msg, 'id') else str(msg)
                            if msg_id not in existing_ids:
                                existing_messages.append(msg)
                                existing_ids.add(msg_id)
                        accumulated_state["messages"] = existing_messages
                    else:
                        accumulated_state.update(node_update)

                # å‘é€çŠ¶æ€æ›´æ–°
                formatted = format_state_update(accumulated_state)
                formatted["data"]["execution_steps"] = execution_steps
                formatted["data"]["step_details"] = step_details
                yield f"data: {json.dumps(formatted, ensure_ascii=False)}\n\n"

        # æ ‡è®°æ‰€æœ‰æ­¥éª¤ä¸ºå®Œæˆ
        for detail in step_details:
            detail["status"] = "completed"

        # å‘é€æœ€ç»ˆçŠ¶æ€
        yield f"data: {json.dumps({'type': 'state_update', 'data': {'execution_steps': execution_steps, 'step_details': step_details}}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"

    except Exception as e:
        logger.error(f"Stream error: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"


def _format_step_name(node_name: str, node_update: Dict[str, Any]) -> Optional[str]:
    """æ ¼å¼åŒ–æ‰§è¡Œæ­¥éª¤åç§°"""
    step_map = {
        "intent_recognition": "ğŸ¯ æ„å›¾è¯†åˆ«",
        "supervisor": "ğŸ§  è·¯ç”±å†³ç­–",
        "rag_agent": "ğŸ“š çŸ¥è¯†æ£€ç´¢",
        "chat_agent": "ğŸ’¬ å¯¹è¯å¤„ç†",
        "product_agent": "ğŸ›ï¸ å•†å“æœç´¢",
        "order_agent": "ğŸ“¦ è®¢å•ç®¡ç†",
    }

    # æ£€æŸ¥æ˜¯å¦æœ‰è·¯ç”±å†³ç­–ä¿¡æ¯
    if node_name == "supervisor" and isinstance(node_update, dict):
        selected_agent = node_update.get("current_agent")
        if selected_agent:
            agent_name = step_map.get(selected_agent, selected_agent)
            return f"ğŸ§  è·¯ç”±åˆ°: {agent_name}"

    return step_map.get(node_name)


def _format_step_detail(node_name: str, node_update: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ‰§è¡Œæ­¥éª¤çš„è¯¦ç»†æè¿°"""
    detail_map = {
        "intent_recognition": "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜æ„å›¾...",
        "supervisor": "æ™ºèƒ½è·¯ç”±æ­£åœ¨é€‰æ‹©æœ€åˆé€‚çš„åŠ©æ‰‹...",
        "rag_agent": "æ­£åœ¨ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯...",
        "chat_agent": "æ­£åœ¨ç”Ÿæˆå›ç­”...",
        "product_agent": "æ­£åœ¨æœç´¢å•†å“ä¿¡æ¯...",
        "order_agent": "æ­£åœ¨æŸ¥è¯¢è®¢å•ä¿¡æ¯...",
    }

    # ç‰¹æ®Šå¤„ç†ï¼šsupervisor è·¯ç”±å†³ç­–
    if node_name == "supervisor" and isinstance(node_update, dict):
        selected_agent = node_update.get("current_agent")
        routing_reason = node_update.get("routing_reason", "")
        if selected_agent:
            agent_descriptions = {
                "rag_agent": "çŸ¥è¯†åº“æ£€ç´¢åŠ©æ‰‹",
                "chat_agent": "æ™ºèƒ½å¯¹è¯åŠ©æ‰‹",
                "product_agent": "å•†å“æœç´¢åŠ©æ‰‹",
                "order_agent": "è®¢å•ç®¡ç†åŠ©æ‰‹",
            }
            desc = agent_descriptions.get(selected_agent, selected_agent)
            if routing_reason:
                return f"å·²é€‰æ‹© {desc}ï¼ŒåŸå› ï¼š{routing_reason[:50]}..."
            return f"å·²é€‰æ‹© {desc}"

    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ä¿¡æ¯
    if isinstance(node_update, dict):
        tools_used = node_update.get("tools_used", [])
        if tools_used:
            tool_names = [t.get("tool", "").split("_")[-1] for t in tools_used if t.get("tool")]
            if tool_names:
                return f"æ­£åœ¨ä½¿ç”¨å·¥å…·ï¼š{', '.join(tool_names)}"

    return detail_map.get(node_name, "æ­£åœ¨å¤„ç†...")


@app.post("/api/chat")
async def chat(request: ChatRequest):
    """èŠå¤©æ¥å£ - æ”¯æŒæµå¼å“åº”"""
    if request.stream:
        return StreamingResponse(
            stream_chat_response(request.message, request.session_id),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    else:
        # éæµå¼å“åº”ï¼ˆåŒæ­¥ï¼‰
        graph = await get_graph()
        final_state = await graph.ainvoke(request.message)
        
        # æ ¼å¼åŒ–å“åº”
        response = format_state_update(final_state)
        return response


@app.get("/api/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    graph_status = "initialized" if _graph is not None else ("initializing" if _graph_initializing else "not_started")
    return {
        "status": "ok",
        "service": "ai-agent-api",
        "graph_status": graph_status
    }


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {"message": "AI Agent API Server", "version": "1.0.0"}


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶é¢„åˆå§‹åŒ– MultiAgentGraphï¼ˆåå°è¿›è¡Œï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰"""
    async def init_graph_background():
        try:
            await get_graph()
        except Exception as e:
            logger.error(f"MultiAgentGraph åå°åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
    
    asyncio.create_task(init_graph_background())


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

