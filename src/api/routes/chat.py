"""èŠå¤©ç›¸å…³è·¯ç”±"""
import json
import logging
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from src.api.models import ChatRequest
from src.api.graph_manager import get_graph
from src.api.formatters import format_state_update, format_step_name, format_step_detail
from src.api.streaming_utils import accumulate_and_format_state_updates

logger = logging.getLogger(__name__)

router = APIRouter()


async def stream_chat_response(question: str, session_id: str):
    """æµå¼ç”ŸæˆèŠå¤©å“åº”"""
    try:
        graph = await get_graph()
        execution_steps: list[str] = []
        step_details: list[dict] = []

        def add_step(step_name: str, detail: str = "") -> bool:
            """æ·»åŠ æ‰§è¡Œæ­¥éª¤ï¼Œè¿”å›æ˜¯å¦æ˜¯æ–°æ­¥éª¤"""
            if step_name and step_name not in execution_steps:
                execution_steps.append(step_name)
                step_details.append({"name": step_name, "detail": detail, "status": "running"})
                # æ›´æ–°ä¹‹å‰æ­¥éª¤çš„çŠ¶æ€ä¸ºå®Œæˆ
                for i in range(len(step_details) - 1):
                    step_details[i]["status"] = "completed"
                return True
            return False

        # ç«‹å³å‘é€åˆå§‹çŠ¶æ€
        initial_step = "ğŸš€ å¼€å§‹åˆ†ææ‚¨çš„é—®é¢˜"
        add_step(initial_step)
        yield f"data: {json.dumps({'type': 'state_update', 'data': {'execution_steps': execution_steps, 'step_details': step_details}}, ensure_ascii=False)}\n\n"

        # é…ç½® checkpointerï¼ˆ2025æœ€ä½³å®è·µï¼šæ˜¾å¼ä¼ é€’ thread_idï¼‰
        config = {
            "configurable": {"thread_id": session_id},
            "recursion_limit": 20
        }

        # ã€å…³é”®ä¿®å¤ã€‘åœ¨æµå¼å¤„ç†ä¹‹å‰ï¼Œå…ˆä» checkpointer è·å–å®Œæ•´çš„çŠ¶æ€ä½œä¸ºåŸºç¡€
        # è¿™æ · accumulated_state ä¼šåŒ…å« task_chainã€entities ç­‰å…³é”®å­—æ®µ
        accumulated_state = {}
        try:
            existing_snapshot = graph.graph.get_state(config)
            if existing_snapshot and existing_snapshot.values:
                # ä½¿ç”¨ç°æœ‰çŠ¶æ€ä½œä¸ºåŸºç¡€ï¼ˆä¿ç•™ task_chain ç­‰å…³é”®æ•°æ®ï¼‰
                # Pydantic æ¨¡å‹ä½¿ç”¨ model_dump() è½¬æ¢ä¸ºå­—å…¸ï¼Œä¸èƒ½ä½¿ç”¨ .copy()
                from src.multi_agent.utils import state_to_dict
                accumulated_state = state_to_dict(existing_snapshot.values)
                logger.info(f"ä» checkpointer åˆå§‹åŒ– accumulated_state: task_chain={'task_chain' in accumulated_state and accumulated_state.get('task_chain') is not None}")
        except Exception as e:
            logger.warning(f"ä» checkpointer è·å–çŠ¶æ€å¤±è´¥: {e}ï¼Œä½¿ç”¨ç©ºçŠ¶æ€åˆå§‹åŒ–")

        # ä½¿ç”¨ updates æ¨¡å¼è·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ›´æ–°
        async for state_update in graph.astream(question, config=config, stream_mode="updates", session_id=session_id):
            # LangGraph è¿”å›çš„æ ¼å¼æ˜¯ {node_name: {updated_fields}}
            for node_name, node_update in state_update.items():
                # è·³è¿‡ç‰¹æ®ŠèŠ‚ç‚¹
                if node_name in ("__start__", "__end__"):
                    continue

                # ç”Ÿæˆæ­¥éª¤åç§°å’Œè¯¦æƒ…
                step_name = format_step_name(node_name, node_update)
                step_detail = format_step_detail(node_name, node_update)

                if step_name:
                    is_new_step = add_step(step_name, step_detail)
                    # å¦‚æœæœ‰æ–°æ­¥éª¤ï¼Œç«‹å³å‘é€
                    if is_new_step:
                        yield f"data: {json.dumps({'type': 'state_update', 'data': {'execution_steps': execution_steps, 'step_details': step_details}}, ensure_ascii=False)}\n\n"

                # ã€å…³é”®ä¿®å¤ã€‘åœ¨æ›´æ–° accumulated_state ä¹‹å‰ï¼Œè®°å½•å½“å‰æ¶ˆæ¯æ•°é‡
                # è¿™æ ·å¯ä»¥åˆ¤æ–­ node_update ä¸­æ˜¯å¦æœ‰æ–°æ¶ˆæ¯
                messages_before_update = len(accumulated_state.get("messages", []))

                # ç´¯ç§¯çŠ¶æ€
                if isinstance(node_update, dict):
                    if "messages" in node_update and "messages" in accumulated_state:
                        # åˆå¹¶ messagesï¼ˆå»é‡ï¼‰
                        existing_messages = accumulated_state.get("messages", [])
                        new_messages = node_update.get("messages", [])
                        existing_ids = {id(msg) if hasattr(msg, 'id') else str(msg) for msg in existing_messages}
                        for msg in new_messages:
                            msg_id = id(msg) if hasattr(msg, 'id') else str(msg)
                            if msg_id not in existing_ids:
                                existing_messages.append(msg)
                                existing_ids.add(msg_id)
                        accumulated_state["messages"] = existing_messages

                        # ã€å…³é”®ä¿®å¤ã€‘ä¹Ÿè¦åˆå¹¶å…¶ä»–å…³é”®å­—æ®µï¼ˆtools_used, current_agent ç­‰ï¼‰
                        for key, value in node_update.items():
                            if key != "messages":
                                # tools_used éœ€è¦åˆå¹¶ï¼ˆåˆ—è¡¨è¿½åŠ ï¼‰
                                if key == "tools_used" and value:
                                    existing_tools = accumulated_state.get("tools_used", [])
                                    accumulated_state["tools_used"] = existing_tools + value
                                else:
                                    # å…¶ä»–å­—æ®µç›´æ¥è¦†ç›–
                                    accumulated_state[key] = value
                    else:
                        accumulated_state.update(node_update)

                # å‘é€çŠ¶æ€æ›´æ–°
                # ã€å…³é”®ä¿®å¤ã€‘ä¼ é€’ node_update å’Œæ›´æ–°å‰çš„æ¶ˆæ¯æ•°é‡ï¼Œä»æºå¤´è§£å†³é—®é¢˜ï¼šåªæå–æ–°æ¶ˆæ¯
                formatted = format_state_update(accumulated_state, node_update, messages_before_update)
                formatted["data"]["execution_steps"] = execution_steps
                formatted["data"]["step_details"] = step_details
                yield f"data: {json.dumps(formatted, ensure_ascii=False)}\n\n"

        # ã€LangGraph 1.xã€‘æµç»“æŸåæ£€æŸ¥æ˜¯å¦æœ‰ interrupt()
        # å½“ interrupt() è¢«è°ƒç”¨æ—¶ï¼Œæµæ­£å¸¸ç»“æŸï¼Œä½†çŠ¶æ€ä¿å­˜åœ¨ checkpointer ä¸­
        # éœ€è¦é€šè¿‡ get_state() æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ interrupt
        try:
            logger.info(f"[chatè·¯ç”±] æµç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ interrupt: session_id={session_id}")
            final_snapshot = graph.graph.get_state(config)
            logger.info(f"[chatè·¯ç”±] checkpointer snapshot: {final_snapshot is not None}, taskså­˜åœ¨: {final_snapshot.tasks is not None if final_snapshot else False}, tasksé•¿åº¦: {len(final_snapshot.tasks) if final_snapshot and final_snapshot.tasks else 0}")
            
            if final_snapshot and final_snapshot.tasks:
                logger.info(f"[chatè·¯ç”±] æ£€æŸ¥ tasks ä¸­çš„ interrupt: tasksæ•°é‡={len(final_snapshot.tasks)}")
                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ interruptï¼ˆLangGraph 1.x å°† interrupt ä¿å­˜åœ¨ tasks ä¸­ï¼‰
                for i, task in enumerate(final_snapshot.tasks):
                    logger.info(f"[chatè·¯ç”±] æ£€æŸ¥ task[{i}]: {type(task)}")
                    # æå– interrupt å€¼
                    for interrupt_obj in (task.interrupts or []):
                        interrupt_value = interrupt_obj.value
                        if interrupt_value and isinstance(interrupt_value, dict):
                            selection_type = interrupt_value.get("selection_type")
                            logger.info(f"[chatè·¯ç”±] interrupt selection_type: {selection_type}")
                            if selection_type == "product":
                                # å‘é€ pending_selection åˆ°å‰ç«¯
                                yield f"data: {json.dumps({'type': 'state_update', 'data': {'response_type': 'selection', 'pending_selection': interrupt_value}}, ensure_ascii=False)}\n\n"
                                logger.info(f"[chatè·¯ç”±] å·²å‘é€ pending_selection: selection_id={interrupt_value.get('selection_id')}")
                        # é€€å‡ºå¾ªç¯ï¼Œåªå¤„ç†ç¬¬ä¸€ä¸ª interrupt
                        break
                    if final_snapshot.tasks[0].interrupts:
                        break
            else:
                logger.info(f"[chatè·¯ç”±] æ²¡æœ‰ interrupt ä»»åŠ¡")
        except Exception as e:
            logger.error(f"[chatè·¯ç”±] æ£€æŸ¥ interrupt çŠ¶æ€å¤±è´¥: {e}", exc_info=True)

        # æ ‡è®°æ‰€æœ‰æ­¥éª¤ä¸ºå®Œæˆ
        for detail in step_details:
            detail["status"] = "completed"

        # å‘é€æœ€ç»ˆçŠ¶æ€
        yield f"data: {json.dumps({'type': 'state_update', 'data': {'execution_steps': execution_steps, 'step_details': step_details}}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"

    except Exception as e:
        logger.error(f"Stream error: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"


@router.delete("/chat/session/{session_id}")
async def clear_session(session_id: str):
    """æ¸…é™¤æŒ‡å®šä¼šè¯çš„çŠ¶æ€

    ç”¨äºé‡ç½®ä¼šè¯ï¼Œæ¸…é™¤ checkpointer ä¸­ä¿å­˜çš„å†å²æ¶ˆæ¯å’ŒçŠ¶æ€ã€‚
    å½“é‡åˆ°æ¶ˆæ¯æ ¼å¼é”™è¯¯æˆ–éœ€è¦é‡æ–°å¼€å§‹å¯¹è¯æ—¶ä½¿ç”¨ã€‚
    """
    try:
        graph = await get_graph()
        config = {"configurable": {"thread_id": session_id}}

        # å°è¯•æ¸…é™¤çŠ¶æ€ï¼ˆé€šè¿‡æ›´æ–°ä¸ºç©ºçŠ¶æ€ï¼‰
        try:
            graph.graph.update_state(
                config,
                {
                    "messages": [],
                    "task_chain": None,
                    "pending_selection": None,
                    "confirmation_pending": None,
                    "entities": {}
                },
                as_node="__start__"
            )

            logger.info(f"å·²æ¸…é™¤ä¼šè¯çŠ¶æ€: {session_id}")
            return {
                "success": True,
                "message": f"ä¼šè¯ {session_id} çš„çŠ¶æ€å·²æ¸…é™¤"
            }
        except Exception as e:
            logger.warning(f"æ¸…é™¤ä¼šè¯çŠ¶æ€æ—¶å‡ºé”™ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
            return {
                "success": True,
                "message": f"ä¼šè¯ {session_id} ä¸å­˜åœ¨æˆ–å·²æ¸…é™¤"
            }

    except Exception as e:
        logger.error(f"æ¸…é™¤ä¼šè¯å¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e)
        }


@router.post("/chat")
async def chat(request: ChatRequest):
    """èŠå¤©æ¥å£ - æ”¯æŒæµå¼å“åº”"""
    if request.stream:
        return StreamingResponse(
            stream_chat_response(request.message, request.session_id),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    else:
        # éæµå¼å“åº”ï¼ˆåŒæ­¥ï¼‰
        graph = await get_graph()

        # é…ç½® checkpointerï¼ˆ2025æœ€ä½³å®è·µï¼šæ˜¾å¼ä¼ é€’ thread_idï¼‰
        config = {
            "configurable": {"thread_id": request.session_id},
            "recursion_limit": 20
        }

        final_state = await graph.ainvoke(request.message, config=config)

        # æ ¼å¼åŒ–å“åº”
        response = format_state_update(final_state)
        return response

