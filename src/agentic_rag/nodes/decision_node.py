"""å†³ç­–èŠ‚ç‚¹å®ç°

æ ¸å¿ƒåŸåˆ™ï¼šç­”æ¡ˆä¼˜å…ˆ + æ™ºèƒ½åˆ¤æ–­
- å…ˆç”Ÿæˆç­”æ¡ˆï¼Œå†æ ¹æ®ç­”æ¡ˆè´¨é‡å†³å®šæ˜¯å¦éœ€è¦æ”¹è¿›æ£€ç´¢
- ä½¿ç”¨ LLM è¯„ä¼°çš„ answer_type æ¥åˆ¤æ–­ç­”æ¡ˆæ˜¯"æ‰¾åˆ°äº†"è¿˜æ˜¯"æ²¡æ‰¾åˆ°"
- é¿å…åœ¨ç”Ÿæˆç­”æ¡ˆå‰è¿‡åº¦ä¼˜åŒ–æ£€ç´¢
"""
from typing import Optional, Dict, Any
from colorama import Fore, Style

from agentic_rag.advance_detector import AdvancedNeedsMoreInfoDetector
from src.agentic_rag.state import AgenticRAGState
from src.agentic_rag.threshold_config import ThresholdConfig


def create_decision_node(
    detector: AdvancedNeedsMoreInfoDetector,
    threshold_config: Optional[ThresholdConfig] = None
):
    """
    åˆ›å»ºå†³ç­–èŠ‚ç‚¹

    Args:
        detector: ä¿¡æ¯éœ€æ±‚æ£€æµ‹å™¨
        threshold_config: é˜ˆå€¼é…ç½®

    Returns:
        å†³ç­–èŠ‚ç‚¹å‡½æ•°
    """
    if threshold_config is None:
        threshold_config = ThresholdConfig.default()

    detector.threshold_config = threshold_config

    def _should_use_adaptive_retrieval(
        iteration: int,
        adaptive_config
    ) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨è‡ªé€‚åº”æ£€ç´¢"""
        return (
            adaptive_config and 
            adaptive_config.enable_progressive_strategy and
            iteration < adaptive_config.max_retrieval_rounds
        )

    def _decide_retrieval_improvement(
        state: AgenticRAGState,
        iteration: int
    ) -> Dict[str, Any]:
        """å†³å®šå¦‚ä½•æ”¹è¿›æ£€ç´¢ï¼ˆç»Ÿä¸€é€»è¾‘ï¼‰"""
        adaptive_config = threshold_config.adaptive_retrieval

        # ä¼˜å…ˆä½¿ç”¨ adaptive_retrieval æ”¹è¿›æ£€ç´¢
        if _should_use_adaptive_retrieval(iteration, adaptive_config):
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ä½¿ç”¨è‡ªé€‚åº”æ£€ç´¢æ”¹è¿›æ£€ç´¢ç­–ç•¥{Style.RESET_ALL}")
            return {
                "next_action": "retrieve",
                "answer": "",
                "iteration_count": iteration + 1
            }

        # å›é€€ç­–ç•¥ï¼šé‡æ–°æ£€ç´¢
        return {
            "next_action": "retrieve",
            "answer": "",
            "iteration_count": iteration + 1
        }

    def decision_node(state: AgenticRAGState) -> AgenticRAGState:
        """
        å†³ç­–èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨

        å†³ç­–æµç¨‹ï¼ˆç­”æ¡ˆä¼˜å…ˆï¼‰ï¼š
        1. æ²¡æœ‰æ–‡æ¡£ â†’ æ£€ç´¢
        2. æœ‰æ–‡æ¡£æ²¡ç­”æ¡ˆ â†’ ç”Ÿæˆç­”æ¡ˆ
        3. æœ‰ç­”æ¡ˆä¸”ç±»å‹ä¸º found â†’ å®Œæˆ
        4. æœ‰ç­”æ¡ˆä½†ç±»å‹ä¸º not_found ä¸”æ£€ç´¢è´¨é‡ä½ â†’ æ”¹è¿›æ£€ç´¢
        5. å…¶ä»–æƒ…å†µæ ¹æ®ç­”æ¡ˆè´¨é‡åˆ¤æ–­

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        iteration = state.get("iteration_count", 0)
        max_iterations = state.get("max_iterations", 3)
        retrieved_docs = state.get("retrieved_docs", [])
        answer = state.get("answer", "")
        retrieval_quality = state.get("retrieval_quality", 0.0)
        answer_quality = state.get("answer_quality", 0.0)
        answer_type = state.get("answer_type", "partial")  # found | not_found | partial

        answer_threshold = threshold_config.decision.answer_quality_threshold
        retrieval_threshold = threshold_config.decision.retrieval_quality_threshold

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if iteration >= max_iterations:
            print(f"\n{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iterations})ï¼Œç»“æŸ{Style.RESET_ALL}")
            return {"next_action": "finish"}

        print(f"\n{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ç¬¬ {iteration + 1} è½®å†³ç­–{Style.RESET_ALL}")

        # ========== æ­¥éª¤1ï¼šæ²¡æœ‰æ–‡æ¡£ â†’ æ£€ç´¢ ==========
        if not retrieved_docs:
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ éœ€è¦æ£€ç´¢æ–‡æ¡£{Style.RESET_ALL}")
            return {"next_action": "retrieve"}

        # ========== æ­¥éª¤2ï¼šæœ‰æ–‡æ¡£æ²¡ç­”æ¡ˆ â†’ ç”Ÿæˆç­”æ¡ˆ ==========
        if not answer:
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ç”Ÿæˆç­”æ¡ˆ (æ£€ç´¢è´¨é‡: {retrieval_quality:.2f}){Style.RESET_ALL}")
            return {"next_action": "generate"}

        # ========== æ­¥éª¤3ï¼šæ ¹æ®ç­”æ¡ˆç±»å‹å’Œè´¨é‡åˆ¤æ–­ ==========
        print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ç­”æ¡ˆç±»å‹: {answer_type}, è´¨é‡: {answer_quality:.2f}, æ£€ç´¢è´¨é‡: {retrieval_quality:.2f}{Style.RESET_ALL}")

        # ç­”æ¡ˆç±»å‹ä¸º "found"ï¼šæˆåŠŸæ‰¾åˆ°ç­”æ¡ˆ
        if answer_type == "found":
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ç­”æ¡ˆå·²æ‰¾åˆ°ï¼Œå®Œæˆ{Style.RESET_ALL}")
            return {"next_action": "finish"}

        # ç­”æ¡ˆç±»å‹ä¸º "not_found"ï¼šæ˜ç¡®è¯´æ²¡æ‰¾åˆ°
        if answer_type == "not_found":
            # æ£€ç´¢è´¨é‡ä½ï¼Œå¯èƒ½æ˜¯æ£€ç´¢é—®é¢˜ï¼Œå°è¯•æ”¹è¿›
            if retrieval_quality < retrieval_threshold and iteration < max_iterations - 1:
                print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ç­”æ¡ˆ'æœªæ‰¾åˆ°'ä¸”æ£€ç´¢è´¨é‡ä½ ({retrieval_quality:.2f})ï¼Œå°è¯•æ”¹è¿›æ£€ç´¢{Style.RESET_ALL}")
                return _decide_retrieval_improvement(state, iteration)
            else:
                # æ£€ç´¢è´¨é‡å·²ç»å¤Ÿé«˜ï¼Œæˆ–å·²è¾¾æœ€åä¸€è½®ï¼Œæ¥å—"æœªæ‰¾åˆ°"
                print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ æ£€ç´¢è´¨é‡å·²è¾¾æ ‡æˆ–å·²è¾¾æœ€åè½®ï¼Œæ¥å—'æœªæ‰¾åˆ°'ç­”æ¡ˆ{Style.RESET_ALL}")
                return {"next_action": "finish"}

        # ç­”æ¡ˆç±»å‹ä¸º "partial"ï¼šéƒ¨åˆ†å›ç­”
        if answer_quality >= answer_threshold:
            # è´¨é‡å¤Ÿé«˜ï¼Œæ¥å—éƒ¨åˆ†ç­”æ¡ˆ
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ éƒ¨åˆ†ç­”æ¡ˆè´¨é‡è‰¯å¥½ ({answer_quality:.2f})ï¼Œå®Œæˆ{Style.RESET_ALL}")
            return {"next_action": "finish"}

        # ========== æ­¥éª¤4ï¼šç­”æ¡ˆè´¨é‡ä¸å¥½ â†’ åˆ¤æ–­å¦‚ä½•æ”¹è¿› ==========
        print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ç­”æ¡ˆè´¨é‡ä¸è¶³ ({answer_quality:.2f} < {answer_threshold:.2f}){Style.RESET_ALL}")

        if iteration >= max_iterations - 1:
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ å·²è¾¾æœ€åä¸€è½®ï¼Œç»“æŸ{Style.RESET_ALL}")
            return {"next_action": "finish"}

        # æ£€æŸ¥å¤±è´¥åˆ†ææ˜¯å¦å»ºè®®é‡æ–°è¿›è¡Œæ„å›¾è¯†åˆ«
        failure_analysis = state.get("failure_analysis")
        intent_reclassification_count = state.get("intent_reclassification_count", 0)
        adaptive_config = threshold_config.adaptive_retrieval
        
        # å¦‚æœå¤±è´¥åˆ†æå»ºè®®é‡æ–°è¿›è¡Œæ„å›¾è¯†åˆ«ï¼Œä¸”æœªè¶…è¿‡æœ€å¤§é‡è¯†åˆ«æ¬¡æ•°
        if (failure_analysis and 
            failure_analysis.get("needs_intent_reclassification") and
            adaptive_config and
            adaptive_config.enable_intent_reclassification and
            intent_reclassification_count < adaptive_config.max_reclassification_count and
            threshold_config.intent_classification.enable_intent_classification):
            
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ å¤±è´¥åˆ†æå»ºè®®é‡æ–°è¿›è¡Œæ„å›¾è¯†åˆ«{Style.RESET_ALL}")
            return {
                "next_action": "reclassify_intent",
                "answer": "",
                "intent_reclassification_count": intent_reclassification_count + 1
            }

        # ä½¿ç”¨ detector åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
        question = state.get("question", "")
        needs_more_info = detector.needs_more_information(
            answer=answer,
            retrieved_docs=retrieved_docs,
            question=question,
            answer_quality=answer_quality
        )

        if not needs_more_info:
            # ä¿¡æ¯è¶³å¤Ÿï¼Œåªæ˜¯ç­”æ¡ˆç”Ÿæˆè´¨é‡å·®ï¼Œé‡æ–°ç”Ÿæˆ
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ ä¿¡æ¯å……è¶³ï¼Œé‡æ–°ç”Ÿæˆç­”æ¡ˆ{Style.RESET_ALL}")
            return {
                "next_action": "generate",
                "answer": "",
                "iteration_count": iteration + 1
            }

        # éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå°è¯•æ”¹è¿›æ£€ç´¢
        print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸ’­ã€decisionã€‘ éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œæ”¹è¿›æ£€ç´¢{Style.RESET_ALL}")
        return _decide_retrieval_improvement(state, iteration)

    return decision_node
