"""Web Search èŠ‚ç‚¹å®ç° (Corrective RAG)"""
from typing import Optional
from colorama import Fore, Style

from src.agentic_rag.state import AgenticRAGState
from src.agentic_rag.threshold_config import ThresholdConfig
from src.agentic_rag.web_search import CorrectiveRAGHandler
from src.agentic_rag.retriever import IntelligentRetriever


def create_web_search_node(
    crag_handler: CorrectiveRAGHandler,
    retriever: Optional[IntelligentRetriever] = None,
    threshold_config: Optional[ThresholdConfig] = None
):
    """
    åˆ›å»º Web Search èŠ‚ç‚¹ (Corrective RAG)

    2025 æœ€ä½³å®è·µï¼šå½“æœ¬åœ°æ£€ç´¢è´¨é‡ä¸è¶³æ—¶ï¼Œä½¿ç”¨ Web æœç´¢è·å–å¤–éƒ¨ä¿¡æ¯

    Args:
        crag_handler: CRAG å¤„ç†å™¨
        retriever: æ™ºèƒ½æ£€ç´¢å™¨ï¼ˆç”¨äºè¯„ä¼°æ£€ç´¢è´¨é‡ï¼‰
        threshold_config: é˜ˆå€¼é…ç½®

    Returns:
        Web Search èŠ‚ç‚¹å‡½æ•°
    """
    if threshold_config is None:
        threshold_config = ThresholdConfig.default()

    def web_search_node(state: AgenticRAGState) -> AgenticRAGState:
        """
        Web Search èŠ‚ç‚¹ï¼šæ‰§è¡Œ Web æœç´¢å¹¶èåˆç»“æœ

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        question = state["question"]
        retrieved_docs = state.get("retrieved_docs", [])
        retrieval_quality = state.get("retrieval_quality", 0.0)
        iteration = state.get("iteration_count", 0)
        web_search_count = state.get("web_search_count", 0)

        print(f"\n{Style.BRIGHT}{Fore.CYAN}ğŸŒã€web_searchèŠ‚ç‚¹ã€‘ æ‰§è¡Œ Web æœç´¢...{Style.RESET_ALL}")
        print(f"{Style.BRIGHT}{Fore.CYAN}æŸ¥è¯¢: {question}{Style.RESET_ALL}")
        print(f"{Style.BRIGHT}{Fore.CYAN}å½“å‰æ£€ç´¢è´¨é‡: {retrieval_quality:.2f}{Style.RESET_ALL}")

        try:
            # ç›´æ¥æ‰§è¡Œ Web æœç´¢ï¼Œä¸å†é‡å¤åˆ¤æ–­
            # æ³¨æ„ï¼šdecision_node å·²ç»åˆ¤æ–­è¿‡éœ€è¦ web_searchï¼Œè¿™é‡Œç›´æ¥æ‰§è¡Œ
            # é¿å… crag_handler.process() å†…éƒ¨çš„ should_trigger_web_search å†æ¬¡åˆ¤æ–­å¯¼è‡´æ­»å¾ªç¯
            web_docs = crag_handler.perform_web_search(question, optimize_query=True)

            if web_docs:
                # ç²¾ç‚¼å¹¶èåˆç»“æœ
                refined_docs = crag_handler.refine_web_results(question, web_docs)
                merged_docs = crag_handler.merge_results(retrieved_docs, refined_docs)
                used_web_search = True
                web_results_count = len(refined_docs)
            else:
                # Web æœç´¢æ²¡æœ‰è¿”å›ç»“æœ
                merged_docs = retrieved_docs
                used_web_search = False  # æ ‡è®°ä¸ºæœªæˆåŠŸä½¿ç”¨ï¼Œä½†ä¸ä¼šæ­»å¾ªç¯å› ä¸º web_search_count ä¼šå¢åŠ 
                web_results_count = 0

            if used_web_search:
                print(f"{Style.BRIGHT}{Fore.CYAN}ğŸŒã€web_searchèŠ‚ç‚¹ã€‘ Web æœç´¢å®Œæˆï¼Œè·å– {web_results_count} ä¸ªç»“æœ{Style.RESET_ALL}")
                print(f"{Style.BRIGHT}{Fore.CYAN}ğŸŒã€web_searchèŠ‚ç‚¹ã€‘ èåˆåå…± {len(merged_docs)} ä¸ªæ–‡æ¡£{Style.RESET_ALL}")
            else:
                print(f"{Style.BRIGHT}{Fore.CYAN}ğŸŒã€web_searchèŠ‚ç‚¹ã€‘ Web æœç´¢æœªè§¦å‘æˆ–ä¸å¯ç”¨{Style.RESET_ALL}")
            
            for doc in web_docs:
                print(f"{Style.BRIGHT}{Fore.CYAN}Web æœç´¢ç»“æœ: {doc.page_content}{Style.RESET_ALL}")
            # æ›´æ–°çŠ¶æ€
            tools_used = state.get("tools_used", [])
            if used_web_search and "web_search" not in tools_used:
                tools_used.append("web_search")

            # æ›´æ–°æ£€ç´¢å†å²
            retrieval_history = state.get("retrieval_history", [])
            if used_web_search:
                retrieval_history.append(merged_docs)

            # è¯„ä¼°åˆå¹¶åçš„æ£€ç´¢è´¨é‡
            new_quality = retrieval_quality  # é»˜è®¤ä¿æŒåŸå€¼
            if retriever and merged_docs:
                quality_threshold = threshold_config.retrieval.quality_threshold
                new_quality, _ = retriever.evaluate_retrieval_quality(
                    question,
                    merged_docs,
                    threshold=quality_threshold
                )
                print(f"{Style.BRIGHT}{Fore.CYAN}ğŸŒã€web_searchèŠ‚ç‚¹ã€‘ æ›´æ–°æ£€ç´¢è´¨é‡: {retrieval_quality:.2f} â†’ {new_quality:.2f}{Style.RESET_ALL}")

            return {
                "retrieved_docs": merged_docs,
                "retrieval_history": retrieval_history,
                "retrieval_quality": new_quality,  # å…³é”®ï¼šæ›´æ–°æ£€ç´¢è´¨é‡
                "web_search_used": used_web_search,
                "web_search_results": web_docs if web_docs else [],
                # å…³é”®ä¿®å¤ï¼šæ— è®ºæˆåŠŸä¸å¦éƒ½å¢åŠ è®¡æ•°ï¼Œé¿å…æ­»å¾ªç¯
                # decision_node ç”¨ web_search_count < 1 æ¥åˆ¤æ–­æ˜¯å¦è¿˜èƒ½è§¦å‘
                "web_search_count": web_search_count + 1,
                "tools_used": tools_used,
                "error_message": ""
            }

        except Exception as e:
            error_msg = f"Web æœç´¢é”™è¯¯: {str(e)}"
            print(f"{Style.BRIGHT}{Fore.YELLOW}ğŸŒã€web_searchèŠ‚ç‚¹ã€‘ âŒ {error_msg}{Style.RESET_ALL}")
            return {
                "error_message": error_msg,
                "web_search_used": False,
                # å³ä½¿å‡ºé”™ä¹Ÿå¢åŠ è®¡æ•°ï¼Œé¿å…æ­»å¾ªç¯
                "web_search_count": web_search_count + 1
            }

    return web_search_node

